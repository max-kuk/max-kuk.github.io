<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Maksim Kukushkin </title> <meta name="author" content="Maksim Kukushkin"> <meta name="description" content="Computer Vision Researcher at University of Leipzig "> <meta name="keywords" content="computer vision, machine learning, deep learning, research, university of leipzig, leipzig, germany"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png?46745b64199a42ffe16f7fdf25862f59"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://max-kuk.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Maksim</span> Kukushkin </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/bimae-480.webp 480w,/assets/img/publication_preview/bimae-800.webp 800w,/assets/img/publication_preview/bimae-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/bimae.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="bimae.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kukushkin2024bimae" class="col-sm-8"> <div class="title">BiMAE-A Bimodal Masked Autoencoder Architecture for Single-Label Hyperspectral Image Classification</div> <div class="author"> Maksim Kukushkin, Martin Bogdan, and Thomas Schmid </div> <div class="periodical"> <em>In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openaccess.thecvf.com/content/CVPR2024W/PBVS/html/Kukushkin_BiMAE_-_A_Bimodal_Masked_Autoencoder_Architecture_for_Single-Label_Hyperspectral_CVPRW_2024_paper.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://github.com/max-kuk/bimae_seed_classification" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/CVPR_2024_Poster.pdf" class="btn btn-sm z-depth-0" role="button">Poster</a> </div> <div class="abstract hidden"> <p>Hyperspectral imaging offers manifold opportunities for applications that may not, or only partially, be achieved within the visual spectrum. Our paper presents a novel approach for Single-Label Hyperspectral Image Classification, demonstrated through the example of a key challenge faced by agricultural seed producers: seed purity testing. We employ Self-Supervised Learning and Masked Image Modeling techniques to tackle this task. Recognizing the challenges and costs associated with acquiring hyperspectral data, we aim to develop a versatile method capable of working with visible, arbitrary combinations of spectral bands (multispectral data) and hyperspectral sensor data. By integrating RGB and hyperspectral data, we leverage the detailed spatial information from RGB images and the rich spectral information from hyperspectral data to enhance the accuracy of seed classification. Through evaluations in various real-life scenarios, we demonstrate the flexibility, scalability, and efficiency of our approach.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">kukushkin2024bimae</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BiMAE-A Bimodal Masked Autoencoder Architecture for Single-Label Hyperspectral Image Classification}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kukushkin, Maksim and Bogdan, Martin and Schmid, Thomas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2987--2996}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/depthwise_morp_ops-480.webp 480w,/assets/img/publication_preview/depthwise_morp_ops-800.webp 800w,/assets/img/publication_preview/depthwise_morp_ops-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/depthwise_morp_ops.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="depthwise_morp_ops.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kukushkin2023morphological" class="col-sm-8"> <div class="title">On optimizing morphological neural networks for hyperspectral image classification</div> <div class="author"> Maksim Kukushkin, Martin Bogdan, and Thomas Schmid </div> <div class="periodical"> <em>In Sixteenth International Conference on Machine Vision (ICMV 2023)</em>, Apr 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://neurophotonics.spiedigitallibrary.org/conference-proceedings-of-spie/13072/1307202/On-optimizing-morphological-neural-networks-for-hyperspectral-image-classification/10.1117/12.3023593.short" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Convolutional Neural Networks have become an important tool for various Computer Vision tasks. Yet, increasing complexity of such architectures drives computational costs. To this end, we propose two measures to achieve similar classification results as state-of-the-art architectures while at the same time reducing model complexity significantly. Firstly, we describe a novel type of non-linear parameter-efficient morphological layers inspired by concepts that are well-known and widely used with convolutions. Secondly, we present a set of simple network architectures, organized as optimization framework, which is enhanced by neural architecture search and hyperparameter optimization. In experiments with hyperspectral remote sensing data, we demonstrate that the identified optimal morphological architecture produces results not only comparable with other architectures from the optimization framework, but also comparable or better than selected state-of-the-art neural network architectures for image classification. Depending on the performed task, the proposed optimized architecture requires up to 25 times fewer parameters than actual state-of-the-art networks.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kukushkin2023morphological</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On optimizing morphological neural networks for hyperspectral image classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Sixteenth International Conference on Machine Vision (ICMV 2023)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{SPIE}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kukushkin, Maksim and Bogdan, Martin and Schmid, Thomas}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Osten, Wolfgang}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1117/12.3023593}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/assembly-480.webp 480w,/assets/img/publication_preview/assembly-800.webp 800w,/assets/img/publication_preview/assembly-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/assembly.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="assembly.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Erichsmeier2024" class="col-sm-8"> <div class="title">Automating the purity analysis of oilseed rape through usage of hyperspectral imaging</div> <div class="author"> Fabian Erichsmeier, Maksim Kukushkin, Johannes Fiedler, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Matthias Enders, Simon Goertz, Martin Bogdan, Thomas Schmid, Reinhard Kaschuba' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In Photonic Technologies in Plant and Agricultural Science</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12879/3002665/Automating-the-purity-analysis-of-oilseed-rape-through-usage-of/10.1117/12.3002665.short" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>The purity analysis of oilseed rape (Brassica napus L.) is currently a labor-intensive and manual process, requiring significant human effort for accurate assessment. In this context, the KIRa-Sorter system presents an innovative solution that leverages hyperspectral imaging technology for automating the comprehensive classification of various contaminants present in rapeseed samples. The initial phase of the KIRa-Sorter system involves the efficient capture of hyperspectral and RGB image data from rapeseed samples as input for classification. From up to 200 different types of foreign objects typically found in these samples, a reduced coreset has been defined that the system is able to automatically singulate, classify and physically sort.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Erichsmeier2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automating the purity analysis of oilseed rape through usage of hyperspectral imaging}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Photonic Technologies in Plant and Agricultural Science}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{SPIE}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Erichsmeier, Fabian and Kukushkin, Maksim and Fiedler, Johannes and Enders, Matthias and Goertz, Simon and Bogdan, Martin and Schmid, Thomas and Kaschuba, Reinhard}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Heinemann, Dag and Polder, Gerrit}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">mar</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1117/12.3002665}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Kukushkin2024bicae" class="col-sm-8"> <div class="title">BiCAE - A Bimodal Convolutional Autoencoder for Seed Purity Testing</div> <div class="author"> Maksim Kukushkin, Martin Bogdan, and Thomas Schmid </div> <div class="periodical"> <em>In Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track (ECML PKDD 2024)</em>, Aug 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/chapter/10.1007/978-3-031-70381-2_28" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://drive.proton.me/urls/1CS8BAZ2ZM#YHmhcPfxXCqp" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Poster</a> </div> <div class="abstract hidden"> <p>In the seed-producing industry, accurate assessment of harvested seeds for technical purity is a necessary, yet time-consuming and labor-intensive task. Automating this task holds immense potential for enhancing agricultural seed productivity, and using computer vision methods to classify seeds has already demonstrated promising results. Here, we propose a novel spectral-enhanced image anomaly detection approach to accurately discriminate Canola seeds (Brassica napus L.) from visually similar non-Canola seeds. Our bimodal approach exploits both RGB and data captured by a hyperspectral camera of the same sample. For efficient processing of this data, we suggest a novel bimodal convolutional autoencoder (BiCAE) architecture, which combines the strengths of high spatial resolution in RGB and high spectral resolution in hyperspectral data. We demonstrate that training our BiCAE model on a Canola dataset allows to learn a joint latent representation that effectively extracts spatio-spectral information from both RGB and hyperspectral data. Experiments show promising results in differentiating between Canola and non-Canola samples, in particular in detecting various types of non-Canola seeds in previously unseen test data. The obtained results highlight the model’s ability to generalize beyond the training data, surpassing unimodal models that rely solely on a single modality.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kukushkin2024bicae</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{BiCAE - A Bimodal Convolutional Autoencoder for Seed Purity Testing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Machine Learning and Knowledge Discovery in Databases. Applied Data Science Track (ECML PKDD 2024)}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kukushkin, Maksim and Bogdan, Martin and Schmid, Thomas}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Bifet, Albert and Krilavivcius, Tomas and Miliou, Ioanna and Nowaczyk, Slawomir}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Nature Switzerland}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Cham}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{447--462}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-70381-2_28}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-70381-2}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/kabr-480.webp 480w,/assets/img/publication_preview/kabr-800.webp 800w,/assets/img/publication_preview/kabr-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/kabr.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="kabr.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kholiavchenko2024" class="col-sm-8"> <div class="title">Deep dive into KABR: a dataset for understanding ungulate behavior from in-situ drone video</div> <div class="author"> Maksim Kholiavchenko, Jenna Kline, Maksim Kukushkin, and <span class="more-authors" title="click to view 17 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '17 more authors' ? 'Otto Brookes, Sam Stevens, Isla Duporge, Alec Sheets, Reshma R. Babu, Namrata Banerji, Elizabeth Campolongo, Matthew Thompson, Nina Van Tiel, Jackson Miliko, Eduardo Bessa, Majid Mirmehdi, Thomas Schmid, Tanya Berger-Wolf, Daniel I. Rubenstein, Tilo Burghardt, Charles V. Stewart' : '17 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">17 more authors</span> </div> <div class="periodical"> <em>Multimedia Tools and Applications</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s11042-024-20512-4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>In this paper, we extend the dataset statistics, model benchmarks, and performance analysis for the recently published KABR dataset, an in situ dataset for ungulate behavior recognition using aerial footage from the Mpala Research Centre in Kenya. The dataset comprises video footage of reticulated giraffes (lat. Giraffa reticulata), Plains zebras (lat. Equus quagga), and Grévy’s zebras (lat. Equus grevyi) captured using a DJI Mavic 2S drone. It includes both spatiotemporal (i.e., mini-scenes) and behavior annotations provided by an expert behavioral ecologist. In total, KABR has more than 10 hours of annotated video. We extend the previous work in four key areas by: (i) providing comprehensive dataset statistics to reveal new insights into the data distribution across behavior classes and species; (ii) extending the set of existing benchmark models to include a new state-of-the-art transformer; (iii) investigating weight initialization strategies and exploring whether pretraining on human action recognition datasets is transferable to in situ animal behavior recognition directly (i.e., zero-shot) or as initialization for end-to-end model training; and (iv) performing a detailed statistical analysis of the performance of these models across species, behavior, and formally defined segments of the long-tailed distribution. The KABR dataset addresses the limitations of previous datasets sourced from controlled environments, offering a more authentic representation of natural animal behaviors. This work marks a significant advancement in the automatic analysis of wildlife behavior, leveraging drone technology to overcome traditional observational challenges and enabling a more nuanced understanding of animal interactions in their natural habitats. The dataset is available at https://kabrdata.xyz</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kholiavchenko2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Deep dive into KABR: a dataset for understanding ungulate behavior from in-situ drone video}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s11042-024-20512-4}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Multimedia Tools and Applications}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer Science and Business Media LLC}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kholiavchenko, Maksim and Kline, Jenna and Kukushkin, Maksim and Brookes, Otto and Stevens, Sam and Duporge, Isla and Sheets, Alec and Babu, Reshma R. and Banerji, Namrata and Campolongo, Elizabeth and Thompson, Matthew and Tiel, Nina Van and Miliko, Jackson and Bessa, Eduardo and Mirmehdi, Majid and Schmid, Thomas and Berger-Wolf, Tanya and Rubenstein, Daniel I. and Burghardt, Tilo and Stewart, Charles V.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/unimodal_models-480.webp 480w,/assets/img/publication_preview/unimodal_models-800.webp 800w,/assets/img/publication_preview/unimodal_models-1400.webp 1400w," sizes="200px" type="image/webp"></source> <img src="/assets/img/publication_preview/unimodal_models.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="unimodal_models.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Kukushkin2022" class="col-sm-8"> <div class="title">Canola seed or not? Autoencoder-based Anomaly Detection in Agricultural Seed Production</div> <div class="author"> Maksim Kukushkin, Matthias Enders, Reinhard Kaschuba, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Martin Bogdan, Thomas Schmid' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em></em> Dec 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.gi.de/items/020df413-5c97-4677-a43c-1c2bad4fb8cf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>Analysing harvested seeds is a time-consuming task in the seed-producing industry. Automating this process has the potential to enhance and expedite agricultural seed production. In our study, we focus on differentiating Canola seeds from visually similar non-Canola seeds using computer vision techniques. Our approach utilises both RGB and hyperspectral images, captured by a specialised camera, to train separate autoencoder neural networks. By leveraging the high spatial resolution of RGB data and the high spectral resolution of hyperspectral data, we develop distinct models for Canola seed analysis, ensuring a comprehensive and robust assessment. The autoencoder networks are trained on a dataset of Canola seeds, allowing for the extraction of latent representations from both RGB and hyperspectral data. This enables efficient compression of input data and effective discrimination between Canola and non-Canola seeds. Our proposed approach demonstrates promising results in detecting non-Canola seeds in unseen test data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Kukushkin2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kukushkin, Maksim and Enders, Matthias and Kaschuba, Reinhard and Bogdan, Martin and Schmid, Thomas}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{anomaly detection,  seed production,  hyperspectral imaging,  autoencoder}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Canola seed or not? Autoencoder-based Anomaly Detection in Agricultural Seed Production}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Gesellschaft f\"{u}r Informatik e.V.}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18420/INF2023_169}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Kukushkin2021" class="col-sm-8"> <div class="title">Automatic acoustic classification of feline sex</div> <div class="author"> Maksim Kukushkin, and Stavros Ntalampiras </div> <div class="periodical"> <em>In Proceedings of the 16th International Audio Mostly Conference</em>, virtual/Trento, Italy, Dec 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1145/3478384.3478385" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="abstract hidden"> <p>This paper presents a novel method for classifying the feline sex based on the respective vocalizations. Due to the size of the available dataset, we rely on tree-based classifiers which can efficiently learn classification rules in such poor data availability cases. More specifically, this work investigates the ability of random forests and boosting classifiers when trained with a wide range of acoustic features derived both from time and frequency domain. The considered classifiers are evaluated using standardized figures of merit including f1-score, recall, precision, and accuracy. The best-performing classifier was the CatBoost, while the obtained results are in line with the state-of-the-art accuracy levels in the field of animal sex classification.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Kukushkin2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kukushkin, Maksim and Ntalampiras, Stavros}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic acoustic classification of feline sex}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450385695}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3478384.3478385}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 16th International Audio Mostly Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{156–160}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{tree-based classifiers, domestic animals, bioacoustics, audio signal processing, audio pattern recognition, Internet of Audio Things.}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{virtual/Trento, Italy}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{AM '21}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Maksim Kukushkin. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>